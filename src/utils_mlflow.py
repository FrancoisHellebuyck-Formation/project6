import mlflow
from mlflow.tracking import MlflowClient
from src.constantes import TRACKING_URI
import matplotlib.pyplot as plt
import pandas as pd
import psutil
import os


def create_experiment_with_metadata(experiment_name, description, tags=None):
    """
    CrÃ©e ou rÃ©cupÃ¨re une expÃ©rience avec description et tags

    Args:
        experiment_name: nom de l'expÃ©rience
        description: description dÃ©taillÃ©e
        tags: dictionnaire de tags (optionnel)

    Returns:
        experiment_id
    """
    mlflow.set_tracking_uri(TRACKING_URI)
    client = MlflowClient()

    # VÃ©rifier si l'expÃ©rience existe
    experiment = client.get_experiment_by_name(experiment_name)

    if experiment is None:
        # CrÃ©er la nouvelle expÃ©rience
        experiment_id = client.create_experiment(experiment_name)
        print(f"âœ… ExpÃ©rience crÃ©Ã©e: {experiment_name}")
    else:
        experiment_id = experiment.experiment_id
        print(f"â„¹ï¸  ExpÃ©rience existante: {experiment_name}")

    # Ajouter la description
    if description:
        client.set_experiment_tag(experiment_id, "mlflow.note.content", description)
        print("âœ… Description ajoutÃ©e")

    # Ajouter les tags
    if tags:
        for key, value in tags.items():
            client.set_experiment_tag(experiment_id, key, value)
        print(f"âœ… {len(tags)} tag(s) ajoutÃ©(s)")

    return experiment_id


def start_experiment(experiment_name, description, tags=None):
    """
    DÃ©marre une expÃ©rience MLflow avec description et tags

    Args:
        experiment_name: nom de l'expÃ©rience
        description: description dÃ©taillÃ©e
        tags: dictionnaire de tags (optionnel)

    Returns:
        experiment_id
    """
    experiment_id = create_experiment_with_metadata(experiment_name, description, tags)
    mlflow.set_experiment(experiment_name)
    return experiment_id


def log_global_params_and_tags(X_train, X_test, df, tags):
    """
    Logue les paramÃ¨tres globaux et les tags pour une expÃ©rience MLflow
    Args:
        X_train: donnÃ©es d'entraÃ®nement
        X_test: donnÃ©es de test
        df: DataFrame complÃ¨te (pour loguer la source des donnÃ©es)
        name: nom du modÃ¨le
        tags: dictionnaire de tags Ã  ajouter
    """
    # Loguer les paramÃ¨tres globaux (une seule fois)
    mlflow.log_param("data_version", "v1.0")
    mlflow.log_param("train_samples", len(X_train))
    mlflow.log_param("test_samples", len(X_test))
    mlflow.log_param("features", X_train.shape[1])

    # Plusieurs tags Ã  la fois
    mlflow.set_tags(tags)

    dataset = mlflow.data.from_pandas(
        df,
        source="data/processed/survey_lung_cancer_features.parquet",
        name="survey_lung_cancer_features",
        targets="LUNG_CANCER",
    )
    mlflow.log_input(dataset, context="training")


def log_base_metrics(accuracy, precision, recall, f1, f2):
    """
    Logue les mÃ©triques de base et affiche le rapport de classification

    Args:
        accuracy: prÃ©cision globale
        precision: prÃ©cision
        recall: rappel
        f1: score F1
        f2: score F2
    """
    # Loguer les mÃ©triques principales
    mlflow.log_metric("accuracy", accuracy)
    mlflow.log_metric("precision", precision)
    mlflow.log_metric("recall", recall)
    mlflow.log_metric("f1-score", f1)
    mlflow.log_metric("f2-score", f2)


def log_complete_system_metrics():
    """Logger toutes les mÃ©triques systÃ¨me pertinentes"""

    # CPU
    cpu_percent = psutil.cpu_percent(interval=1, percpu=False)
    cpu_count = psutil.cpu_count()

    # MÃ©moire
    memory = psutil.virtual_memory()

    # Disque
    disk = psutil.disk_usage("/")

    # Process actuel
    process = psutil.Process()
    process_memory = process.memory_info()

    metrics = {
        # CPU
        "system_cpu_percent": cpu_percent,
        "system_cpu_count": cpu_count,
        # MÃ©moire systÃ¨me
        "system_memory_total_gb": memory.total / (1024**3),
        "system_memory_available_gb": memory.available / (1024**3),
        "system_memory_used_percent": memory.percent,
        # Disque
        "system_disk_used_percent": disk.percent,
        "system_disk_free_gb": disk.free / (1024**3),
        # Process
        "process_memory_rss_mb": process_memory.rss / (1024**2),
        "process_memory_vms_mb": process_memory.vms / (1024**2),
    }

    return metrics


def log_feature_importance_with_names(pipeline, X_train, mlflow_enabled=True):
    """
    Logger les feature importances avec les vrais noms des features

    Args:
        pipeline: Pipeline sklearn/imblearn
        X_train: DonnÃ©es d'entraÃ®nement (DataFrame ou array)
        mlflow_enabled: Logger dans MLflow ou non
    """

    # Extraire le modÃ¨le LightGBM
    if hasattr(pipeline, "named_steps"):
        lgb_model = pipeline.named_steps.get("classifier") or pipeline.named_steps.get(
            "model"
        )
    else:
        lgb_model = pipeline

    # RÃ©cupÃ©rer les noms des features ORIGINAUX
    if hasattr(X_train, "columns"):
        feature_names = X_train.columns.tolist()
    elif hasattr(lgb_model, "feature_name_"):
        # Essayer de rÃ©cupÃ©rer depuis le modÃ¨le
        feature_names = lgb_model.feature_name_
    else:
        # Fallback : noms gÃ©nÃ©riques
        n_features = len(lgb_model.feature_importances_)
        feature_names = [f"feature_{i}" for i in range(n_features)]

    # RÃ©cupÃ©rer les importances
    feature_importances = lgb_model.feature_importances_

    # VÃ©rifier que les longueurs correspondent
    if len(feature_names) != len(feature_importances):
        print(f"âš ï¸  Nombre de features: {len(feature_names)}")
        print(f"âš ï¸  Nombre d'importances: {len(feature_importances)}")
        # Ajuster si nÃ©cessaire
        if len(feature_names) > len(feature_importances):
            feature_names = feature_names[: len(feature_importances)]
        else:
            feature_names = feature_names + [
                f"feature_{i}"
                for i in range(len(feature_names), len(feature_importances))
            ]

    # CrÃ©er le DataFrame
    fi_df = pd.DataFrame(
        {"feature": feature_names, "importance": feature_importances}
    ).sort_values("importance", ascending=False)

    fi_df["rank"] = range(1, len(fi_df) + 1)

    # Afficher
    print("\nðŸŽ¯ Top 20 Features:")
    print(fi_df.head(20).to_string(index=False))

    # === GRAPHIQUE ===
    fig, axes = plt.subplots(1, 2, figsize=(16, 8))

    # Graphique 1 : Top 20
    top_20 = fi_df.head(20)
    axes[0].barh(range(len(top_20)), top_20["importance"], color="steelblue")
    axes[0].set_yticks(range(len(top_20)))
    axes[0].set_yticklabels(top_20["feature"], fontsize=10)
    axes[0].set_xlabel("Importance", fontsize=12, fontweight="bold")
    axes[0].set_ylabel("Feature", fontsize=12, fontweight="bold")
    axes[0].set_title("Top 20 Feature Importances", fontsize=14, fontweight="bold")
    axes[0].invert_yaxis()
    axes[0].grid(axis="x", alpha=0.3)

    # Graphique 2 : Distribution des importances
    axes[1].hist(
        fi_df["importance"], bins=30, color="coral", edgecolor="black", alpha=0.7
    )
    axes[1].set_xlabel("Importance Value", fontsize=12, fontweight="bold")
    axes[1].set_ylabel("Number of Features", fontsize=12, fontweight="bold")
    axes[1].set_title(
        "Distribution of Feature Importances", fontsize=14, fontweight="bold"
    )
    axes[1].grid(axis="y", alpha=0.3)

    plt.tight_layout()
    plt.savefig("feature_importance_complete.png", dpi=150, bbox_inches="tight")

    if mlflow_enabled:
        mlflow.log_artifact("feature_importance_complete.png")

    plt.close()

    if mlflow_enabled:
        os.remove("feature_importance_complete.png")

    # === CSV ===
    fi_df.to_csv("feature_importance.csv", index=False)

    if mlflow_enabled:
        mlflow.log_artifact("feature_importance.csv")
        os.remove("feature_importance.csv")

    # === LOGGER TOP 10 DANS MLFLOW ===
    if mlflow_enabled:
        for i, row in enumerate(fi_df.head(10).itertuples(), 1):
            mlflow.log_metric(f"top_{i}_importance", float(row.importance))
            mlflow.log_param(f"top_{i}_feature", row.feature)

    print("âœ… Feature importances sauvegardÃ©es avec les vrais noms!")

    return fi_df
